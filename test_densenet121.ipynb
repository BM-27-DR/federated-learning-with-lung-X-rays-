{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f62bec4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17710,
     "status": "ok",
     "timestamp": 1748583797189,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "3f62bec4",
    "outputId": "7092a59e-f3a9-4770-97a9-2d619c53d8de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision==0.15.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio==2.0.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.0.1) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1) (3.1.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1) (2.8.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision==0.15.2) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision==0.15.2) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision==0.15.2) (11.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision==0.15.2) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision==0.15.2) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision==0.15.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision==0.15.2) (3.10)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fedml in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.6)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.8.4)\n",
      "Requirement already satisfied: cachetools in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (6.0.0)\n",
      "Requirement already satisfied: python-rapidjson>=0.9.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.20)\n",
      "Requirement already satisfied: click in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (8.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (3.10.3)\n",
      "Requirement already satisfied: geventhttpclient<=2.0.9,>=1.4.4 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.0.9)\n",
      "Requirement already satisfied: chardet in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (5.2.0)\n",
      "Requirement already satisfied: toposort in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.10)\n",
      "Requirement already satisfied: httpx in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.28.1)\n",
      "Requirement already satisfied: dill in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.4.0)\n",
      "Requirement already satisfied: onnx in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.17.0)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.0.41)\n",
      "Requirement already satisfied: wandb==0.13.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.13.2)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.20.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (3.20.3)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.70.18)\n",
      "Requirement already satisfied: py-machineid in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.8.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.11.5)\n",
      "Requirement already satisfied: attrs in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (25.3.0)\n",
      "Requirement already satisfied: smart-open==6.3.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (6.3.0)\n",
      "Requirement already satisfied: tritonclient in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.58.0)\n",
      "Requirement already satisfied: pytest-mock in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (3.14.1)\n",
      "Requirement already satisfied: prettytable in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (3.16.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.115.12)\n",
      "Requirement already satisfied: wget in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (3.2)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.34.3)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (3.12.7)\n",
      "Requirement already satisfied: requests<2.32 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.31.0)\n",
      "Requirement already satisfied: torchvision>=0.14.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.15.2+cu118)\n",
      "Requirement already satisfied: networkx<3.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.8.8)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.6.1)\n",
      "Requirement already satisfied: GPUtil in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.4.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (8.4.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (3.13.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from fedml) (4.14.0)\n",
      "Requirement already satisfied: paho-mqtt<2.0.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.6.1)\n",
      "Requirement already satisfied: boto3 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.38.28)\n",
      "Requirement already satisfied: torch>=1.13.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.0.1+cu118)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (6.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.2.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.9.4)\n",
      "Requirement already satisfied: gensim in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (4.3.3)\n",
      "Requirement already satisfied: redis in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (6.2.0)\n",
      "Requirement already satisfied: attrdict in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (2.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (1.26.4)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (5.3.1)\n",
      "Requirement already satisfied: docker==6.1.3 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (6.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (4.67.1)\n",
      "Requirement already satisfied: ntplib in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.4.0)\n",
      "Requirement already satisfied: fastapi-cli==0.0.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fedml) (0.0.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker==6.1.3->fedml) (2.4.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker==6.1.3->fedml) (1.8.0)\n",
      "Requirement already satisfied: packaging>=14.0 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from docker==6.1.3->fedml) (25.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from docker==6.1.3->fedml) (310)\n",
      "Requirement already satisfied: importlib_metadata<2.0,>=1.5 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi-cli==0.0.1->fedml) (1.7.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb==0.13.2->fedml) (2.29.1)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from wandb==0.13.2->fedml) (1.17.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb==0.13.2->fedml) (3.1.44)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb==0.13.2->fedml) (1.0.13)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb==0.13.2->fedml) (2.3)\n",
      "Requirement already satisfied: pathtools in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb==0.13.2->fedml) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb==0.13.2->fedml) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from wandb==0.13.2->fedml) (7.0.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb==0.13.2->fedml) (1.3.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wandb==0.13.2->fedml) (65.5.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp>=3.8.1->fedml) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp>=3.8.1->fedml) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp>=3.8.1->fedml) (1.20.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp>=3.8.1->fedml) (0.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp>=3.8.1->fedml) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp>=3.8.1->fedml) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp>=3.8.1->fedml) (1.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from click->fedml) (0.4.6)\n",
      "Requirement already satisfied: brotli in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from geventhttpclient<=2.0.9,>=1.4.4->fedml) (1.1.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from geventhttpclient<=2.0.9,>=1.4.4->fedml) (2025.4.26)\n",
      "Requirement already satisfied: gevent>=0.13 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from geventhttpclient<=2.0.9,>=1.4.4->fedml) (25.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<2.32->fedml) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<2.32->fedml) (3.10)\n",
      "Requirement already satisfied: sympy in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.13.1->fedml) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.13.1->fedml) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.13.1->fedml) (3.1.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision>=0.14.1->fedml) (11.2.1)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.28 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3->fedml) (1.38.28)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3->fedml) (0.13.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3->fedml) (1.0.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi->fedml) (0.46.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->fedml) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->fedml) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->fedml) (0.7.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim->fedml) (1.13.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->fedml) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->fedml) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx->fedml) (0.16.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->fedml) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->fedml) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->fedml) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->fedml) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->fedml) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->fedml) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->fedml) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->fedml) (2025.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from prettytable->fedml) (0.2.13)\n",
      "Requirement already satisfied: winregistry<3.0.0,>=2.0.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from py-machineid->fedml) (2.1.1)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from pytest->fedml) (2.19.1)\n",
      "Requirement already satisfied: exceptiongroup>=1 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from pytest->fedml) (1.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytest->fedml) (1.6.0)\n",
      "Requirement already satisfied: iniconfig>=1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytest->fedml) (2.1.0)\n",
      "Requirement already satisfied: tomli>=1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytest->fedml) (2.2.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->fedml) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->fedml) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sqlalchemy->fedml) (3.2.2)\n",
      "Requirement already satisfied: zope.event in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient<=2.0.9,>=1.4.4->fedml) (5.0)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient<=2.0.9,>=1.4.4->fedml) (7.2)\n",
      "Requirement already satisfied: cffi>=1.17.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient<=2.0.9,>=1.4.4->fedml) (1.17.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from GitPython>=1.0.0->wandb==0.13.2->fedml) (4.0.12)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib_metadata<2.0,>=1.5->fastapi-cli==0.0.1->fedml) (3.22.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx->fedml) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.13.1->fedml) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.13.1->fedml) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.17.1->gevent>=0.13->geventhttpclient<=2.0.9,>=1.4.4->fedml) (2.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.13.2->fedml) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install fedml\n",
    "%pip install scikit-learn pandas\n",
    "%pip install imbalanced-learn\n",
    "%pip install matplotlib seaborn\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5398535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "     ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.6/39.5 MB 20.5 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 1.5/39.5 MB 19.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 2.2/39.5 MB 15.2 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 2.8/39.5 MB 16.1 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 3.4/39.5 MB 16.8 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 4.1/39.5 MB 16.4 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 4.8/39.5 MB 17.1 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 5.5/39.5 MB 16.7 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 6.2/39.5 MB 16.5 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 7.0/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 7.7/39.5 MB 17.0 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 8.4/39.5 MB 16.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 9.1/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 9.9/39.5 MB 17.1 MB/s eta 0:00:02\n",
      "     ---------- ---------------------------- 10.8/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 11.6/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 12.3/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 13.0/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 13.7/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 14.5/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 15.3/39.5 MB 17.7 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 16.2/39.5 MB 17.7 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 16.8/39.5 MB 17.7 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 17.6/39.5 MB 17.7 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 18.5/39.5 MB 17.7 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 19.3/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 19.9/39.5 MB 16.8 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 20.7/39.5 MB 17.2 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 21.6/39.5 MB 17.7 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 22.5/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 23.3/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 24.2/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 25.1/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 25.9/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 26.8/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 27.7/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 28.5/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 29.2/39.5 MB 16.8 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 30.0/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 30.8/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 31.7/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 32.6/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 33.4/39.5 MB 17.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 34.2/39.5 MB 17.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 34.9/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 35.7/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 36.6/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 37.4/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 38.3/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  39.2/39.5 MB 17.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  39.5/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  39.5/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  39.5/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  39.5/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  39.5/39.5 MB 17.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 39.5/39.5 MB 12.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "IgotTdHvg11A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IgotTdHvg11A",
    "outputId": "6cf6100d-4395-4183-c90e-a63586c8d8e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opacus==1.3.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opacus==1.3.0) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opacus==1.3.0) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.8 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opacus==1.3.0) (2.0.1+cu118)\n",
      "Requirement already satisfied: opt-einsum>=3.3.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opacus==1.3.0) (3.4.0)\n",
      "Requirement already satisfied: functorch in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opacus==1.3.0) (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8->opacus==1.3.0) (3.18.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8->opacus==1.3.0) (2.8.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\bikram\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8->opacus==1.3.0) (4.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8->opacus==1.3.0) (3.1.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8->opacus==1.3.0) (1.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.8->opacus==1.3.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bikram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.8->opacus==1.3.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opacus==1.3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c921c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "executionInfo": {
     "elapsed": 165,
     "status": "error",
     "timestamp": 1748583815500,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "053c921c",
    "outputId": "7bc5dd66-eb2a-4661-a0ec-5a9da50f88b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Torch version: 2.0.1+cu118\n",
      " CUDA available: True\n",
      " GPU device: NVIDIA T1000 8GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "#  Differential Privacy with Opacus\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "#  Federated Learning (FedML)\n",
    "from fedml import FedMLRunner  \n",
    "#  Data Handling and ML Evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "#  Imbalanced Data Handling\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#  Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#  Progress Bar\n",
    "from tqdm import tqdm\n",
    "#  System & Debugging\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#  Check GPU device\n",
    "print(\" Torch version:\", torch.__version__)\n",
    "print(\" CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\" GPU device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30919ad",
   "metadata": {
    "id": "e30919ad"
   },
   "source": [
    "Define Global Configurations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a542ae7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1748496938514,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "4a542ae7",
    "outputId": "2fd68f2b-6c6d-40bf-c338-a9027ca2dfd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "class Args:\n",
    "    # Data and model config\n",
    "    image_size = 224\n",
    "    num_classes = 3  # 0: COVID, 1: Pneumonia, 2: Normal\n",
    "    batch_size = 32\n",
    "    lr = 0.01\n",
    "    epochs = 7\n",
    "\n",
    "    # Differential privacy config \n",
    "    noise_multiplier = 1.0\n",
    "    max_grad_norm = 1.0\n",
    "    delta = 1e-5  # For epsilon calculation\n",
    "\n",
    "    # Federated Learning config\n",
    "    round_count = 10              \n",
    "    client_sizes = [3, 7, 10, 13]  \n",
    "    initial_clients = 6           \n",
    "    drop_rate = 0.2                \n",
    "\n",
    "    # Hardware config\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Seed for reproducibility\n",
    "    seed = 42\n",
    "\n",
    "args = Args()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "print(\"Configuration loaded. Using device:\", args.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c21813",
   "metadata": {
    "id": "80c21813"
   },
   "source": [
    "Load and Clean dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a693881c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1748496981446,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "a693881c",
    "outputId": "ed813bee-2b99-44e6-949c-534ab113527f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total image paths collected: 26381\n",
      " Train set size: 21104 samples\n",
      " Test set size: 5277 samples\n",
      "\n",
      " Training class distribution:\n",
      "   Pneumonia (Label 1): 8985 samples\n",
      "   Normal (Label 2): 9226 samples\n",
      "   COVID (Label 0): 2893 samples\n",
      "\n",
      " Testing class distribution:\n",
      "   COVID (Label 0): 723 samples\n",
      "   Pneumonia (Label 1): 2247 samples\n",
      "   Normal (Label 2): 2307 samples\n",
      " Training dataset ready with 21104 samples.\n",
      " Testing dataset ready with 5277 samples.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((args.image_size, args.image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def collect_image_paths(folder_path, label):\n",
    "    dataset = []\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(folder_path, fname)\n",
    "            dataset.append((img_path, label))\n",
    "    return dataset\n",
    "\n",
    "covid_path = \"COVID-19_Radiography_Dataset\"\n",
    "covid_images = collect_image_paths(os.path.join(covid_path, \"COVID/images\"), label=0)\n",
    "viral_images = collect_image_paths(os.path.join(covid_path, \"Viral_Pneumonia/images\"), label=1)\n",
    "lung_opacity_images = collect_image_paths(os.path.join(covid_path, \"Lung_Opacity/images\"), label=1)\n",
    "normal_images_covid = collect_image_paths(os.path.join(covid_path, \"Normal/images\"), label=2)\n",
    "\n",
    "pneu_path = \"chest_xray\"\n",
    "normal_images_pneu = collect_image_paths(os.path.join(pneu_path, \"train/NORMAL\"), label=2)\n",
    "pneumonia_images = collect_image_paths(os.path.join(pneu_path, \"train/PNEUMONIA\"), label=1)\n",
    "\n",
    "all_image_paths = (\n",
    "    covid_images +\n",
    "    viral_images +\n",
    "    lung_opacity_images +\n",
    "    normal_images_covid +\n",
    "    normal_images_pneu +\n",
    "    pneumonia_images\n",
    ")\n",
    "\n",
    "print(f\" Total image paths collected: {len(all_image_paths)}\")\n",
    "\n",
    "def split_train_test(data, test_size=0.2, random_state=42):\n",
    " \n",
    "    paths = [item[0] for item in data]\n",
    "    labels = [item[1] for item in data]\n",
    "    \n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "        paths, labels, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state, \n",
    "        stratify=labels\n",
    "    )\n",
    "\n",
    "    train_data = list(zip(train_paths, train_labels))\n",
    "    test_data = list(zip(test_paths, test_labels))\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "train_image_paths, test_image_paths = split_train_test(all_image_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\" Train set size: {len(train_image_paths)} samples\")\n",
    "print(f\" Test set size: {len(test_image_paths)} samples\")\n",
    "\n",
    "def print_class_distribution(data, dataset_name):\n",
    "    class_counts = {}\n",
    "    for _, label in data:\n",
    "        class_counts[label] = class_counts.get(label, 0) + 1\n",
    "    \n",
    "    print(f\"\\n {dataset_name} class distribution:\")\n",
    "    class_names = {0: \"COVID\", 1: \"Pneumonia\", 2: \"Normal\"}\n",
    "    for label, count in class_counts.items():\n",
    "        print(f\"   {class_names[label]} (Label {label}): {count} samples\")\n",
    "\n",
    "print_class_distribution(train_image_paths, \"Training\")\n",
    "print_class_distribution(test_image_paths, \"Testing\")\n",
    "class XrayLazyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_or_img, label = self.data[idx]\n",
    "        try:\n",
    "            if isinstance(path_or_img, str):\n",
    "                img = Image.open(path_or_img).convert(\"RGB\")\n",
    "            else:\n",
    "                img = path_or_img\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Skipping {path_or_img} due to error: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.data)) \n",
    "\n",
    "train_dataset = XrayLazyDataset(train_image_paths, transform=img_transform)\n",
    "test_dataset = XrayLazyDataset(test_image_paths, transform=img_transform)\n",
    "\n",
    "print(f\" Training dataset ready with {len(train_dataset)} samples.\")\n",
    "print(f\" Testing dataset ready with {len(test_dataset)} samples.\")\n",
    "\n",
    "def create_client_datasets(train_data, test_data, num_clients):\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(test_data)\n",
    "    \n",
    "    # Calculate samples per client\n",
    "    train_samples_per_client = len(train_data) // num_clients\n",
    "    test_samples_per_client = len(test_data) // num_clients\n",
    "    \n",
    "    client_datasets = {}\n",
    "    \n",
    "    for client_id in range(num_clients):\n",
    "        train_start = client_id * train_samples_per_client\n",
    "        train_end = (client_id + 1) * train_samples_per_client if client_id < num_clients - 1 else len(train_data)\n",
    "        \n",
    "        test_start = client_id * test_samples_per_client\n",
    "        test_end = (client_id + 1) * test_samples_per_client if client_id < num_clients - 1 else len(test_data)\n",
    "        \n",
    "        # Create client-specific data\n",
    "        client_train_data = train_data[train_start:train_end]\n",
    "        client_test_data = test_data[test_start:test_end]\n",
    "        \n",
    "        # Create datasets for this client\n",
    "        client_train_dataset = XrayLazyDataset(client_train_data, transform=img_transform)\n",
    "        client_test_dataset = XrayLazyDataset(client_test_data, transform=img_transform)\n",
    "        \n",
    "        client_datasets[f'client_{client_id}'] = {\n",
    "            'train': client_train_dataset,\n",
    "            'test': client_test_dataset\n",
    "        }\n",
    "        \n",
    "        print(f\" Client {client_id}: Train={len(client_train_dataset)}, Test={len(client_test_dataset)}\")\n",
    "    \n",
    "    return client_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daed181",
   "metadata": {
    "id": "6daed181"
   },
   "source": [
    "Plot the distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49adfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1748497005024,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "4d49adfa",
    "outputId": "a859910e-816e-45d1-b5a2-0b10a125292a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label counts: Counter({'Normal': 11533, 'Pneumonia': 11232, 'COVID-19': 3616})\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Use the already collected image paths and labels\n",
    "all_labels = [label for _, label in all_image_paths]\n",
    "\n",
    "# Label mapping for display\n",
    "label_map = {0: \"COVID-19\", 1: \"Pneumonia\", 2: \"Normal\"}\n",
    "label_names = [label_map[l] for l in all_labels]\n",
    "\n",
    "counter = Counter(label_names)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(counter.keys(), counter.values(), color=[\"red\", \"orange\", \"green\"])\n",
    "plt.title(\"Class Distribution in Combined Dataset\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\" Label counts:\", counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326aac27",
   "metadata": {
    "id": "326aac27"
   },
   "source": [
    "Data Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbb6da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1748497009035,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "a2cbb6da",
    "outputId": "4a9a762c-fd57-4bb3-82df-cf8543b873f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Augmentation transforms defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((args.image_size, args.image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Augmented transform: for training or oversampled data (COVID)\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.Resize((args.image_size, args.image_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\" Augmentation transforms defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f469fe",
   "metadata": {
    "id": "d9f469fe"
   },
   "source": [
    "Split the data among the clients and smote the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bde21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38943,
     "status": "ok",
     "timestamp": 1748497050924,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "1e2bde21",
    "outputId": "931ca93e-203d-48f2-b53a-c3338a49a874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts:\n",
      " - COVID: 3616\n",
      " - Pneumonia: 11232\n",
      " - Normal: 11533\n",
      " Combined + balanced dataset size: 34298\n",
      "Client 0: 4572 train, 1144 test samples\n",
      "Client 1: 4572 train, 1144 test samples\n",
      "Client 2: 4572 train, 1144 test samples\n",
      "Client 3: 4572 train, 1144 test samples\n",
      "Client 4: 4572 train, 1144 test samples\n",
      "Client 5: 4574 train, 1144 test samples\n",
      " Created 6 federated clients with train-test splits.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "covid_augment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "])\n",
    "\n",
    "\n",
    "label_map = {0: \"COVID\", 1: \"Pneumonia\", 2: \"Normal\"}\n",
    "class_data = defaultdict(list)\n",
    "\n",
    "for path, label in all_image_paths:\n",
    "    class_data[label].append((path, label))\n",
    "\n",
    "print(\"Original class counts:\")\n",
    "for lbl, items in class_data.items():\n",
    "    print(f\" - {label_map[lbl]}: {len(items)}\")\n",
    "\n",
    "target_class_size = max(len(v) for v in class_data.values())\n",
    "augmented_covid_data = class_data[0].copy()\n",
    "\n",
    "while len(augmented_covid_data) < target_class_size:\n",
    "    img_path, label = random.choice(class_data[0])\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        aug_img = covid_augment(img)\n",
    "        augmented_covid_data.append((aug_img, label))  \n",
    "    except Exception as e:\n",
    "        print(f\" Augmentation failed on {img_path}: {e}\")\n",
    "\n",
    "combined_dataset = (\n",
    "    augmented_covid_data +\n",
    "    class_data[1] +  # Pneumonia\n",
    "    class_data[2]    # Normal\n",
    ")\n",
    "\n",
    "random.shuffle(combined_dataset)\n",
    "print(f\" Combined + balanced dataset size: {len(combined_dataset)}\")\n",
    "\n",
    "def split_among_clients(dataset, num_clients, train_ratio=0.8):\n",
    "    random.shuffle(dataset)\n",
    "    total = len(dataset)\n",
    "    split_size = total // num_clients\n",
    "    clients = {}\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        start = i * split_size\n",
    "        end = (i + 1) * split_size if i != num_clients - 1 else total\n",
    "        client_data = dataset[start:end]\n",
    "\n",
    "        # Train-test split\n",
    "        split_idx = int(train_ratio * len(client_data))\n",
    "        train_data = client_data[:split_idx]\n",
    "        test_data = client_data[split_idx:]\n",
    "\n",
    "        clients[i] = {\n",
    "            'train': train_data,\n",
    "            'test': test_data\n",
    "        }\n",
    "\n",
    "        print(f\"Client {i}: {len(train_data)} train, {len(test_data)} test samples\")\n",
    "\n",
    "    return clients\n",
    "\n",
    "client_datasets = split_among_clients(combined_dataset, args.initial_clients)\n",
    "\n",
    "print(f\" Created {args.initial_clients} federated clients with train-test splits.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d1957",
   "metadata": {
    "id": "871d1957"
   },
   "source": [
    "Load and Customize DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c670f05d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1748497075412,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "c670f05d",
    "outputId": "090361f2-5f00-4997-e300-91593a5f3399"
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.models import densenet121\n",
    "\n",
    "model = densenet121(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False  \n",
    "\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_features, args.num_classes)\n",
    "model = model.to(args.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c7137e",
   "metadata": {
    "id": "14c7137e"
   },
   "source": [
    "Local Training with Opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f7163dd",
   "metadata": {
    "id": "1f7163dd"
   },
   "outputs": [],
   "source": [
    "from opacus import PrivacyEngine\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_local_model(client_id, model, train_data, test_data, args):\n",
    "    # Deep copy the global model\n",
    "    model = copy.deepcopy(model).to(args.device)\n",
    "    model.train()\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    # Optimizer and loss\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Attach Privacy Engine\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    model, optimizer, train_loader = privacy_engine.make_private(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        noise_multiplier=args.noise_multiplier,\n",
    "        max_grad_norm=args.max_grad_norm,\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(args.epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(args.device), labels.to(args.device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"[Client {client_id}] Epoch {epoch+1}/{args.epochs}, Loss: {running_loss:.4f}\")\n",
    "\n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(args.device), labels.to(args.device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"[Client {client_id}] Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    # Privacy accounting\n",
    "    epsilon = privacy_engine.get_epsilon(delta=args.delta)\n",
    "    print(f\"[Client {client_id}] Training done.  = {epsilon:.2f}\")\n",
    "\n",
    "    return model.state_dict(), epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be271d",
   "metadata": {
    "id": "62be271d"
   },
   "source": [
    "FedAvg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae23ac1",
   "metadata": {
    "id": "fae23ac1"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def fed_avg(client_weights):\n",
    "    avg_weights = copy.deepcopy(client_weights[0])\n",
    "\n",
    "    # Sum all the client weights\n",
    "    for key in avg_weights.keys():\n",
    "        for i in range(1, len(client_weights)):\n",
    "            avg_weights[key] += client_weights[i][key]\n",
    "        avg_weights[key] = avg_weights[key] / len(client_weights)\n",
    "\n",
    "    return avg_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687d404",
   "metadata": {
    "id": "6687d404"
   },
   "source": [
    "Inttermittent Client Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6010b3f",
   "metadata": {
    "id": "d6010b3f"
   },
   "outputs": [],
   "source": [
    "def select_clients(client_datasets, round_idx, drop_rate=0.2, seed=None):\n",
    "    total_clients = len(client_datasets)\n",
    "    available_clients = list(client_datasets.keys())\n",
    "    if seed is not None:\n",
    "        random.seed(seed + round_idx)  # Different pattern each round, but reproducible\n",
    "    elif hasattr(args, \"seed\"):\n",
    "        random.seed(args.seed + round_idx)\n",
    "    num_drop = int(total_clients * drop_rate)\n",
    "    random.shuffle(available_clients)\n",
    "    selected_clients = available_clients[num_drop:]\n",
    "\n",
    "    print(f\" Round {round_idx+1}: Selected {len(selected_clients)} out of {total_clients} clients\")\n",
    "    return selected_clients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa92df87",
   "metadata": {
    "id": "aa92df87"
   },
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae295b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "error",
     "timestamp": 1748502942362,
     "user": {
      "displayName": "Bikram Mukherjee",
      "userId": "06654060310173054496"
     },
     "user_tz": -330
    },
    "id": "5ae295b0",
    "outputId": "cf75eb70-5de0-492c-fe17-1e473f6d5c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models\\global_model_round_8.pt\n",
      "\n",
      " -------- Federated Round 9 --------\n",
      " Round 9: Selected 5 out of 6 clients\n",
      "[Client 0] Epoch 1/7, Loss: 74.4951\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 126\u001b[0m\n\u001b[0;32m    123\u001b[0m test_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_dataset) \u001b[38;5;241m-\u001b[39m train_len\n\u001b[0;32m    124\u001b[0m train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m random_split(full_dataset, [train_len, test_len])\n\u001b[1;32m--> 126\u001b[0m updated_weights, epsilon \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_local_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m client_weights\u001b[38;5;241m.\u001b[39mappend(updated_weights)\n\u001b[0;32m    128\u001b[0m epsilons\u001b[38;5;241m.\u001b[39mappend(epsilon)\n",
      "Cell \u001b[1;32mIn[14], line 41\u001b[0m, in \u001b[0;36mtrain_local_model\u001b[1;34m(client_id, model, train_data, test_data, args)\u001b[0m\n\u001b[0;32m     39\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     40\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 41\u001b[0m         running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluation on test set\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import densenet121\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "NUM_CLASSES = 3\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Dataset that handles both file paths and PIL images\n",
    "class XrayLazyDataset(Dataset):\n",
    "    def __init__(self, image_label_list, transform=None):\n",
    "        self.image_label_list = image_label_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_label_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_or_path, label = self.image_label_list[idx]\n",
    "\n",
    "        if isinstance(image_or_path, str):\n",
    "            image = Image.open(image_or_path).convert(\"RGB\")\n",
    "        elif isinstance(image_or_path, Image.Image):\n",
    "            image = image_or_path\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported image type: {type(image_or_path)}\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Strip Opacus prefixes if present\n",
    "def strip_opacus_prefix(state_dict):\n",
    "    return {k.replace(\"_module.\", \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(model, dataset, args):\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=args.batch_size)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(args.device), labels.to(args.device)\n",
    "\n",
    "            if not torch.all((labels >= 0) & (labels < NUM_CLASSES)):\n",
    "                print(f\" Invalid labels found: {labels}\")\n",
    "                continue\n",
    "\n",
    "            outputs = model(images)\n",
    "            if outputs.shape[1] != NUM_CLASSES:\n",
    "                raise RuntimeError(f\" Model output shape {outputs.shape[1]}  NUM_CLASSES {NUM_CLASSES}\")\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Create and return a fresh DenseNet121 model\n",
    "def create_densenet121_model():\n",
    "    model = densenet121(pretrained=True)\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, NUM_CLASSES)\n",
    "    return model\n",
    "\n",
    "# Load the latest saved global model if exists\n",
    "def load_latest_model():\n",
    "    files = [f for f in os.listdir(MODEL_DIR) if f.startswith('global_model_round_') and f.endswith('.pt')]\n",
    "    if not files:\n",
    "        print(\"No previously saved model found. Initializing new model.\")\n",
    "        return create_densenet121_model(), 0\n",
    "    latest_round = max([int(f.split('_')[-1].split('.')[0]) for f in files])\n",
    "    latest_file = os.path.join(MODEL_DIR, f\"global_model_round_{latest_round}.pt\")\n",
    "    print(f\"Loading model from {latest_file}\")\n",
    "    model = create_densenet121_model()\n",
    "    model.load_state_dict(torch.load(latest_file))\n",
    "    return model, latest_round\n",
    "\n",
    "# Load or initialize global model\n",
    "global_model, start_round = load_latest_model()\n",
    "global_model = global_model.to(args.device)\n",
    "global_weights = global_model.state_dict()\n",
    "epsilon_tracker = []\n",
    "round_times = []\n",
    "test_accuracies = []\n",
    "\n",
    "for round_idx in range(start_round, args.round_count):\n",
    "    print(f\"\\n -------- Federated Round {round_idx + 1} --------\")\n",
    "\n",
    "    selected_clients = select_clients(client_datasets, round_idx, drop_rate=args.drop_rate)\n",
    "    client_weights = []\n",
    "    epsilons = []\n",
    "    round_test_acc = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for client_id in selected_clients:\n",
    "        client_data = client_datasets[client_id]\n",
    "\n",
    "        client_data_list = client_data['train'] + client_data['test']\n",
    "        client_data_list = [\n",
    "            (p, l) for (p, l) in client_data_list\n",
    "            if (isinstance(p, str) and os.path.isfile(p)) or isinstance(p, Image.Image)\n",
    "        ]\n",
    "\n",
    "        if len(client_data_list) == 0:\n",
    "            print(f\"[Skip] Client {client_id} has no valid data.\")\n",
    "            continue\n",
    "\n",
    "        full_dataset = XrayLazyDataset(client_data_list, transform=img_transform)\n",
    "        train_len = int(0.8 * len(full_dataset))\n",
    "        test_len = len(full_dataset) - train_len\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_len, test_len])\n",
    "\n",
    "        updated_weights, epsilon = train_local_model(client_id, global_model, train_dataset, test_dataset, args)\n",
    "        client_weights.append(updated_weights)\n",
    "        epsilons.append(epsilon)\n",
    "\n",
    "        temp_model = copy.deepcopy(global_model).to(args.device)\n",
    "        temp_model.load_state_dict(strip_opacus_prefix(updated_weights))\n",
    "        acc = evaluate_model(temp_model, test_dataset, args)\n",
    "        round_test_acc.append(acc)\n",
    "        print(f\"[Client {client_id}]  Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    if client_weights:\n",
    "        global_weights = fed_avg(client_weights)\n",
    "        global_weights = strip_opacus_prefix(global_weights)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        avg_epsilon = sum(epsilons) / len(epsilons)\n",
    "        avg_test_acc = sum(round_test_acc) / len(round_test_acc)\n",
    "        epsilon_tracker.append(avg_epsilon)\n",
    "        test_accuracies.append(avg_test_acc)\n",
    "\n",
    "        round_time = time.time() - start_time\n",
    "        round_times.append(round_time)\n",
    "\n",
    "        print(f\" Round {round_idx + 1} complete. Avg  = {avg_epsilon:.2f}, Avg Test Acc = {avg_test_acc:.2f}% | Time: {round_time:.1f}s\")\n",
    "\n",
    "        combined_test_data = []\n",
    "        for cid, cdata in client_datasets.items():\n",
    "            combined_test_data += [\n",
    "                (p, l) for (p, l) in cdata['test']\n",
    "                if (isinstance(p, str) and os.path.isfile(p)) or isinstance(p, Image.Image)\n",
    "            ]\n",
    "\n",
    "        if len(combined_test_data) > 0:\n",
    "            global_test_dataset = XrayLazyDataset(combined_test_data, transform=img_transform)\n",
    "            global_test_acc = evaluate_model(global_model.to(args.device), global_test_dataset, args)\n",
    "            print(f\"  Global Model Accuracy (All Clients' Test Sets): {global_test_acc:.2f}%\")\n",
    "        else:\n",
    "            print(\" No valid test data found for global model evaluation.\")\n",
    "\n",
    "        model_path = os.path.join(MODEL_DIR, f\"global_model_round_{round_idx+1}.pt\")\n",
    "        torch.save(global_model.state_dict(), model_path)\n",
    "        print(f\" Saved global model to {model_path}\")\n",
    "    else:\n",
    "        print(\" No valid client updates this round. Skipping FedAvg.\")\n",
    "\n",
    "print(\"\\n Federated training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2d9adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from densenet121\\global_model_round_1.pt\n",
      "\n",
      " -------- Federated Round 2 --------\n",
      " Round 2: Selected 5 out of 6 clients\n",
      "[Client 4] Epoch 1/7, Loss: 111.1871\n",
      "[Client 4] Epoch 2/7, Loss: 108.6476\n",
      "[Client 4] Epoch 3/7, Loss: 104.3795\n",
      "[Client 4] Epoch 4/7, Loss: 103.0191\n",
      "[Client 4] Epoch 5/7, Loss: 99.8774\n",
      "[Client 4] Epoch 6/7, Loss: 97.4316\n",
      "[Client 4] Epoch 7/7, Loss: 94.3928\n",
      "[Client 4] Test Accuracy: 73.78%\n",
      "[Client 4] Training done.  = 1.25\n",
      "[Client 4]  Test Accuracy: 73.78%\n",
      "[Client 3] Epoch 1/7, Loss: 111.1350\n",
      "[Client 3] Epoch 2/7, Loss: 107.4910\n",
      "[Client 3] Epoch 3/7, Loss: 104.8638\n",
      "[Client 3] Epoch 4/7, Loss: 101.0849\n",
      "[Client 3] Epoch 5/7, Loss: 98.1431\n",
      "[Client 3] Epoch 6/7, Loss: 96.3947\n",
      "[Client 3] Epoch 7/7, Loss: 94.8432\n",
      "[Client 3] Test Accuracy: 72.12%\n",
      "[Client 3] Training done.  = 1.25\n",
      "[Client 3]  Test Accuracy: 72.12%\n",
      "[Client 1] Epoch 1/7, Loss: 112.5036\n",
      "[Client 1] Epoch 2/7, Loss: 110.2024\n",
      "[Client 1] Epoch 3/7, Loss: 106.8728\n",
      "[Client 1] Epoch 4/7, Loss: 103.5895\n",
      "[Client 1] Epoch 5/7, Loss: 100.9887\n",
      "[Client 1] Epoch 6/7, Loss: 97.5583\n",
      "[Client 1] Epoch 7/7, Loss: 96.3762\n",
      "[Client 1] Test Accuracy: 79.28%\n",
      "[Client 1] Training done.  = 1.25\n",
      "[Client 1]  Test Accuracy: 79.28%\n",
      "[Client 2] Epoch 1/7, Loss: 110.8906\n",
      "[Client 2] Epoch 2/7, Loss: 107.3625\n",
      "[Client 2] Epoch 3/7, Loss: 103.8556\n",
      "[Client 2] Epoch 4/7, Loss: 101.6283\n",
      "[Client 2] Epoch 5/7, Loss: 98.6919\n",
      "[Client 2] Epoch 6/7, Loss: 97.5245\n",
      "[Client 2] Epoch 7/7, Loss: 92.6883\n",
      "[Client 2] Test Accuracy: 75.61%\n",
      "[Client 2] Training done.  = 1.25\n",
      "[Client 2]  Test Accuracy: 75.61%\n",
      "[Client 0] Epoch 1/7, Loss: 110.8995\n",
      "[Client 0] Epoch 2/7, Loss: 107.5517\n",
      "[Client 0] Epoch 3/7, Loss: 106.0426\n",
      "[Client 0] Epoch 4/7, Loss: 100.7537\n",
      "[Client 0] Epoch 5/7, Loss: 98.2430\n",
      "[Client 0] Epoch 6/7, Loss: 97.7382\n",
      "[Client 0] Epoch 7/7, Loss: 94.6045\n",
      "[Client 0] Test Accuracy: 76.14%\n",
      "[Client 0] Training done.  = 1.25\n",
      "[Client 0]  Test Accuracy: 76.14%\n",
      " Round 2 complete. Avg  = 1.25, Avg Test Acc = 0.75% | Time: 1679.4s\n",
      "  Global Model Metrics after Round 2:\n",
      "    Accuracy:  0.7637\n",
      "    Precision: 0.7666\n",
      "    Recall:    0.7636\n",
      "    F1 Score:  0.7621\n",
      "    Confusion Matrix:\n",
      "[[1944   65  261]\n",
      " [ 432 1526  300]\n",
      " [ 241  323 1772]]\n",
      " Saved global model to densenet121\\global_model_round_2.pt\n",
      "\n",
      " -------- Federated Round 3 --------\n",
      " Round 3: Selected 5 out of 6 clients\n",
      "[Client 1] Epoch 1/7, Loss: 94.5669\n",
      "[Client 1] Epoch 2/7, Loss: 92.6355\n",
      "[Client 1] Epoch 3/7, Loss: 89.0501\n",
      "[Client 1] Epoch 4/7, Loss: 88.9634\n",
      "[Client 1] Epoch 5/7, Loss: 86.9360\n",
      "[Client 1] Epoch 6/7, Loss: 87.2053\n",
      "[Client 1] Epoch 7/7, Loss: 87.3869\n",
      "[Client 1] Test Accuracy: 80.59%\n",
      "[Client 1] Training done.  = 1.25\n",
      "[Client 1]  Test Accuracy: 80.59%\n",
      "[Client 5] Epoch 1/7, Loss: 92.9567\n",
      "[Client 5] Epoch 2/7, Loss: 91.6198\n",
      "[Client 5] Epoch 3/7, Loss: 89.3588\n",
      "[Client 5] Epoch 4/7, Loss: 89.4637\n",
      "[Client 5] Epoch 5/7, Loss: 86.1653\n",
      "[Client 5] Epoch 6/7, Loss: 86.7260\n",
      "[Client 5] Epoch 7/7, Loss: 85.0352\n",
      "[Client 5] Test Accuracy: 77.97%\n",
      "[Client 5] Training done.  = 1.25\n",
      "[Client 5]  Test Accuracy: 77.97%\n",
      "[Client 0] Epoch 1/7, Loss: 90.9160\n",
      "[Client 0] Epoch 2/7, Loss: 91.2549\n",
      "[Client 0] Epoch 3/7, Loss: 90.5873\n",
      "[Client 0] Epoch 4/7, Loss: 87.6401\n",
      "[Client 0] Epoch 5/7, Loss: 84.2707\n",
      "[Client 0] Epoch 6/7, Loss: 84.5561\n",
      "[Client 0] Epoch 7/7, Loss: 84.4302\n",
      "[Client 0] Test Accuracy: 79.81%\n",
      "[Client 0] Training done.  = 1.25\n",
      "[Client 0]  Test Accuracy: 79.81%\n",
      "[Client 4] Epoch 1/7, Loss: 93.5055\n",
      "[Client 4] Epoch 2/7, Loss: 90.3706\n",
      "[Client 4] Epoch 3/7, Loss: 86.7830\n",
      "[Client 4] Epoch 4/7, Loss: 86.1660\n",
      "[Client 4] Epoch 5/7, Loss: 86.3119\n",
      "[Client 4] Epoch 6/7, Loss: 82.9152\n",
      "[Client 4] Epoch 7/7, Loss: 84.2091\n",
      "[Client 4] Test Accuracy: 78.15%\n",
      "[Client 4] Training done.  = 1.25\n",
      "[Client 4]  Test Accuracy: 78.15%\n",
      "[Client 3] Epoch 1/7, Loss: 93.5906\n",
      "[Client 3] Epoch 2/7, Loss: 91.8640\n",
      "[Client 3] Epoch 3/7, Loss: 88.0655\n",
      "[Client 3] Epoch 4/7, Loss: 87.7212\n",
      "[Client 3] Epoch 5/7, Loss: 87.7454\n",
      "[Client 3] Epoch 6/7, Loss: 85.0264\n",
      "[Client 3] Epoch 7/7, Loss: 82.0501\n",
      "[Client 3] Test Accuracy: 77.97%\n",
      "[Client 3] Training done.  = 1.25\n",
      "[Client 3]  Test Accuracy: 77.97%\n",
      " Round 3 complete. Avg  = 1.25, Avg Test Acc = 0.79% | Time: 1746.9s\n",
      "  Global Model Metrics after Round 3:\n",
      "    Accuracy:  0.7845\n",
      "    Precision: 0.7859\n",
      "    Recall:    0.7843\n",
      "    F1 Score:  0.7839\n",
      "    Confusion Matrix:\n",
      "[[1905   75  290]\n",
      " [ 329 1628  301]\n",
      " [ 171  313 1852]]\n",
      " Saved global model to densenet121\\global_model_round_3.pt\n",
      "\n",
      " -------- Federated Round 4 --------\n",
      " Round 4: Selected 5 out of 6 clients\n",
      "[Client 0] Epoch 1/7, Loss: 81.6972\n",
      "[Client 0] Epoch 2/7, Loss: 80.5120\n",
      "[Client 0] Epoch 3/7, Loss: 80.3798\n",
      "[Client 0] Epoch 4/7, Loss: 79.4378\n",
      "[Client 0] Epoch 5/7, Loss: 75.7361\n",
      "[Client 0] Epoch 6/7, Loss: 78.6193\n",
      "[Client 0] Epoch 7/7, Loss: 77.4269\n",
      "[Client 0] Test Accuracy: 80.24%\n",
      "[Client 0] Training done.  = 1.25\n",
      "[Client 0]  Test Accuracy: 80.24%\n",
      "[Client 1] Epoch 1/7, Loss: 84.6703\n",
      "[Client 1] Epoch 2/7, Loss: 81.7485\n",
      "[Client 1] Epoch 3/7, Loss: 81.0771\n",
      "[Client 1] Epoch 4/7, Loss: 80.7441\n",
      "[Client 1] Epoch 5/7, Loss: 79.2496\n",
      "[Client 1] Epoch 6/7, Loss: 81.1049\n",
      "[Client 1] Epoch 7/7, Loss: 78.6651\n",
      "[Client 1] Test Accuracy: 80.07%\n",
      "[Client 1] Training done.  = 1.25\n",
      "[Client 1]  Test Accuracy: 80.07%\n",
      "[Client 4] Epoch 1/7, Loss: 80.3527\n",
      "[Client 4] Epoch 2/7, Loss: 81.9611\n",
      "[Client 4] Epoch 3/7, Loss: 79.8513\n",
      "[Client 4] Epoch 4/7, Loss: 80.8731\n",
      "[Client 4] Epoch 5/7, Loss: 81.1799\n",
      "[Client 4] Epoch 6/7, Loss: 78.7949\n",
      "[Client 4] Epoch 7/7, Loss: 78.9401\n",
      "[Client 4] Test Accuracy: 79.72%\n",
      "[Client 4] Training done.  = 1.25\n",
      "[Client 4]  Test Accuracy: 79.72%\n",
      "[Client 3] Epoch 1/7, Loss: 82.4215\n",
      "[Client 3] Epoch 2/7, Loss: 81.9575\n",
      "[Client 3] Epoch 3/7, Loss: 80.9774\n",
      "[Client 3] Epoch 4/7, Loss: 80.2999\n",
      "[Client 3] Epoch 5/7, Loss: 80.0744\n",
      "[Client 3] Epoch 6/7, Loss: 77.3214\n",
      "[Client 3] Epoch 7/7, Loss: 79.2714\n",
      "[Client 3] Test Accuracy: 77.97%\n",
      "[Client 3] Training done.  = 1.25\n",
      "[Client 3]  Test Accuracy: 77.97%\n",
      "[Client 2] Epoch 1/7, Loss: 82.9280\n",
      "[Client 2] Epoch 2/7, Loss: 79.6960\n",
      "[Client 2] Epoch 3/7, Loss: 78.8768\n",
      "[Client 2] Epoch 4/7, Loss: 78.7738\n",
      "[Client 2] Epoch 5/7, Loss: 75.6041\n",
      "[Client 2] Epoch 6/7, Loss: 76.5009\n",
      "[Client 2] Epoch 7/7, Loss: 76.2624\n",
      "[Client 2] Test Accuracy: 79.20%\n",
      "[Client 2] Training done.  = 1.25\n",
      "[Client 2]  Test Accuracy: 79.20%\n",
      " Round 4 complete. Avg  = 1.25, Avg Test Acc = 0.79% | Time: 1683.7s\n",
      "  Global Model Metrics after Round 4:\n",
      "    Accuracy:  0.7997\n",
      "    Precision: 0.8021\n",
      "    Recall:    0.7994\n",
      "    F1 Score:  0.7999\n",
      "    Confusion Matrix:\n",
      "[[1864   87  319]\n",
      " [ 241 1711  306]\n",
      " [ 121  301 1914]]\n",
      " Saved global model to densenet121\\global_model_round_4.pt\n",
      "\n",
      " -------- Federated Round 5 --------\n",
      " Round 5: Selected 5 out of 6 clients\n",
      "[Client 4] Epoch 1/7, Loss: 79.7713\n",
      "[Client 4] Epoch 2/7, Loss: 76.0112\n",
      "[Client 4] Epoch 3/7, Loss: 75.9064\n",
      "[Client 4] Epoch 4/7, Loss: 79.1886\n",
      "[Client 4] Epoch 5/7, Loss: 75.2813\n",
      "[Client 4] Epoch 6/7, Loss: 75.6887\n",
      "[Client 4] Epoch 7/7, Loss: 75.8471\n",
      "[Client 4] Test Accuracy: 78.23%\n",
      "[Client 4] Training done.  = 1.25\n",
      "[Client 4]  Test Accuracy: 78.23%\n",
      "[Client 2] Epoch 1/7, Loss: 78.0871\n",
      "[Client 2] Epoch 2/7, Loss: 77.7396\n",
      "[Client 2] Epoch 3/7, Loss: 74.8996\n",
      "[Client 2] Epoch 4/7, Loss: 73.1804\n",
      "[Client 2] Epoch 5/7, Loss: 73.8035\n",
      "[Client 2] Epoch 6/7, Loss: 72.7869\n",
      "[Client 2] Epoch 7/7, Loss: 75.3072\n",
      "[Client 2] Test Accuracy: 80.07%\n",
      "[Client 2] Training done.  = 1.25\n",
      "[Client 2]  Test Accuracy: 80.07%\n",
      "[Client 5] Epoch 1/7, Loss: 80.7361\n",
      "[Client 5] Epoch 2/7, Loss: 77.5200\n",
      "[Client 5] Epoch 3/7, Loss: 78.8875\n",
      "[Client 5] Epoch 4/7, Loss: 77.2343\n",
      "[Client 5] Epoch 5/7, Loss: 73.5626\n",
      "[Client 5] Epoch 6/7, Loss: 74.6921\n",
      "[Client 5] Epoch 7/7, Loss: 73.8222\n",
      "[Client 5] Test Accuracy: 79.72%\n",
      "[Client 5] Training done.  = 1.25\n",
      "[Client 5]  Test Accuracy: 79.72%\n",
      "[Client 3] Epoch 1/7, Loss: 78.6161\n",
      "[Client 3] Epoch 2/7, Loss: 78.2773\n",
      "[Client 3] Epoch 3/7, Loss: 78.4092\n",
      "[Client 3] Epoch 4/7, Loss: 80.2836\n",
      "[Client 3] Epoch 5/7, Loss: 78.4563\n",
      "[Client 3] Epoch 6/7, Loss: 74.2934\n",
      "[Client 3] Epoch 7/7, Loss: 76.3698\n",
      "[Client 3] Test Accuracy: 81.91%\n",
      "[Client 3] Training done.  = 1.25\n",
      "[Client 3]  Test Accuracy: 81.91%\n",
      "[Client 0] Epoch 1/7, Loss: 72.9225\n",
      "[Client 0] Epoch 2/7, Loss: 75.7609\n",
      "[Client 0] Epoch 3/7, Loss: 74.9697\n",
      "[Client 0] Epoch 4/7, Loss: 73.6637\n",
      "[Client 0] Epoch 5/7, Loss: 74.8483\n",
      "[Client 0] Epoch 6/7, Loss: 75.6912\n",
      "[Client 0] Epoch 7/7, Loss: 75.5109\n",
      "[Client 0] Test Accuracy: 80.16%\n",
      "[Client 0] Training done.  = 1.25\n",
      "[Client 0]  Test Accuracy: 80.16%\n",
      " Round 5 complete. Avg  = 1.25, Avg Test Acc = 0.80% | Time: 1669.0s\n",
      "  Global Model Metrics after Round 5:\n",
      "    Accuracy:  0.8003\n",
      "    Precision: 0.8039\n",
      "    Recall:    0.8005\n",
      "    F1 Score:  0.8012\n",
      "    Confusion Matrix:\n",
      "[[1821  159  290]\n",
      " [ 150 1855  253]\n",
      " [  99  420 1817]]\n",
      " Saved global model to densenet121\\global_model_round_5.pt\n",
      "\n",
      " -------- Federated Round 6 --------\n",
      " Round 6: Selected 5 out of 6 clients\n",
      "[Client 1] Epoch 1/7, Loss: 75.7753\n",
      "[Client 1] Epoch 2/7, Loss: 76.0892\n",
      "[Client 1] Epoch 3/7, Loss: 76.0475\n",
      "[Client 1] Epoch 4/7, Loss: 77.0934\n",
      "[Client 1] Epoch 5/7, Loss: 74.5142\n",
      "[Client 1] Epoch 6/7, Loss: 73.6002\n",
      "[Client 1] Epoch 7/7, Loss: 76.0214\n",
      "[Client 1] Test Accuracy: 81.29%\n",
      "[Client 1] Training done.  = 1.25\n",
      "[Client 1]  Test Accuracy: 81.29%\n",
      "[Client 5] Epoch 1/7, Loss: 74.4063\n",
      "[Client 5] Epoch 2/7, Loss: 77.0158\n",
      "[Client 5] Epoch 3/7, Loss: 75.1207\n",
      "[Client 5] Epoch 4/7, Loss: 77.3858\n",
      "[Client 5] Epoch 5/7, Loss: 74.0107\n",
      "[Client 5] Epoch 6/7, Loss: 76.9178\n",
      "[Client 5] Epoch 7/7, Loss: 76.4236\n",
      "[Client 5] Test Accuracy: 80.42%\n",
      "[Client 5] Training done.  = 1.25\n",
      "[Client 5]  Test Accuracy: 80.42%\n",
      "[Client 3] Epoch 1/7, Loss: 76.5289\n",
      "[Client 3] Epoch 2/7, Loss: 76.8937\n",
      "[Client 3] Epoch 3/7, Loss: 75.3414\n",
      "[Client 3] Epoch 4/7, Loss: 74.7147\n",
      "[Client 3] Epoch 5/7, Loss: 76.4019\n",
      "[Client 3] Epoch 6/7, Loss: 78.8688\n",
      "[Client 3] Epoch 7/7, Loss: 73.6767\n",
      "[Client 3] Test Accuracy: 82.43%\n",
      "[Client 3] Training done.  = 1.25\n",
      "[Client 3]  Test Accuracy: 82.43%\n",
      "[Client 0] Epoch 1/7, Loss: 75.6599\n",
      "[Client 0] Epoch 2/7, Loss: 74.7528\n",
      "[Client 0] Epoch 3/7, Loss: 75.8883\n",
      "[Client 0] Epoch 4/7, Loss: 76.5691\n",
      "[Client 0] Epoch 5/7, Loss: 76.1288\n",
      "[Client 0] Epoch 6/7, Loss: 77.7168\n",
      "[Client 0] Epoch 7/7, Loss: 75.1378\n",
      "[Client 0] Test Accuracy: 80.68%\n",
      "[Client 0] Training done.  = 1.25\n",
      "[Client 0]  Test Accuracy: 80.68%\n",
      "[Client 2] Epoch 1/7, Loss: 75.8830\n",
      "[Client 2] Epoch 2/7, Loss: 74.0331\n",
      "[Client 2] Epoch 3/7, Loss: 73.3250\n",
      "[Client 2] Epoch 4/7, Loss: 72.3883\n",
      "[Client 2] Epoch 5/7, Loss: 73.8766\n",
      "[Client 2] Epoch 6/7, Loss: 73.4014\n",
      "[Client 2] Epoch 7/7, Loss: 76.7827\n",
      "[Client 2] Test Accuracy: 80.51%\n",
      "[Client 2] Training done.  = 1.25\n",
      "[Client 2]  Test Accuracy: 80.51%\n",
      " Round 6 complete. Avg  = 1.25, Avg Test Acc = 0.81% | Time: 1745.0s\n",
      "  Global Model Metrics after Round 6:\n",
      "    Accuracy:  0.8033\n",
      "    Precision: 0.8074\n",
      "    Recall:    0.8035\n",
      "    F1 Score:  0.8043\n",
      "    Confusion Matrix:\n",
      "[[1817  165  288]\n",
      " [ 140 1862  256]\n",
      " [  95  406 1835]]\n",
      " Saved global model to densenet121\\global_model_round_6.pt\n",
      "\n",
      " -------- Federated Round 7 --------\n",
      " Round 7: Selected 5 out of 6 clients\n",
      "[Client 3] Epoch 1/7, Loss: 74.3232\n",
      "[Client 3] Epoch 2/7, Loss: 74.0823\n",
      "[Client 3] Epoch 3/7, Loss: 78.1103\n",
      "[Client 3] Epoch 4/7, Loss: 69.9767\n",
      "[Client 3] Epoch 5/7, Loss: 72.9608\n",
      "[Client 3] Epoch 6/7, Loss: 74.0728\n",
      "[Client 3] Epoch 7/7, Loss: 77.2373\n",
      "[Client 3] Test Accuracy: 79.90%\n",
      "[Client 3] Training done.  = 1.25\n",
      "[Client 3]  Test Accuracy: 79.90%\n",
      "[Client 5] Epoch 1/7, Loss: 75.1767\n",
      "[Client 5] Epoch 2/7, Loss: 73.9821\n",
      "[Client 5] Epoch 3/7, Loss: 77.9778\n",
      "[Client 5] Epoch 4/7, Loss: 75.5362\n",
      "[Client 5] Epoch 5/7, Loss: 74.5207\n",
      "[Client 5] Epoch 6/7, Loss: 77.2368\n",
      "[Client 5] Epoch 7/7, Loss: 76.9033\n",
      "[Client 5] Test Accuracy: 78.23%\n",
      "[Client 5] Training done.  = 1.25\n",
      "[Client 5]  Test Accuracy: 78.23%\n",
      "[Client 1] Epoch 1/7, Loss: 73.5236\n",
      "[Client 1] Epoch 2/7, Loss: 71.3545\n",
      "[Client 1] Epoch 3/7, Loss: 77.1203\n",
      "[Client 1] Epoch 4/7, Loss: 76.3731\n",
      "[Client 1] Epoch 5/7, Loss: 76.6510\n",
      "[Client 1] Epoch 6/7, Loss: 76.7942\n",
      "[Client 1] Epoch 7/7, Loss: 74.3053\n",
      "[Client 1] Test Accuracy: 80.07%\n",
      "[Client 1] Training done.  = 1.25\n",
      "[Client 1]  Test Accuracy: 80.07%\n",
      "[Client 2] Epoch 1/7, Loss: 72.9153\n",
      "[Client 2] Epoch 2/7, Loss: 76.7977\n",
      "[Client 2] Epoch 3/7, Loss: 76.7550\n",
      "[Client 2] Epoch 4/7, Loss: 76.5504\n",
      "[Client 2] Epoch 5/7, Loss: 71.2329\n",
      "[Client 2] Epoch 6/7, Loss: 73.2010\n",
      "[Client 2] Epoch 7/7, Loss: 76.1941\n",
      "[Client 2] Test Accuracy: 79.55%\n",
      "[Client 2] Training done.  = 1.25\n",
      "[Client 2]  Test Accuracy: 79.55%\n",
      "[Client 4] Epoch 1/7, Loss: 74.4728\n",
      "[Client 4] Epoch 2/7, Loss: 76.1386\n",
      "[Client 4] Epoch 3/7, Loss: 76.5050\n",
      "[Client 4] Epoch 4/7, Loss: 71.7858\n",
      "[Client 4] Epoch 5/7, Loss: 75.9220\n",
      "[Client 4] Epoch 6/7, Loss: 73.1066\n",
      "[Client 4] Epoch 7/7, Loss: 75.3027\n",
      "[Client 4] Test Accuracy: 79.90%\n",
      "[Client 4] Training done.  = 1.25\n",
      "[Client 4]  Test Accuracy: 79.90%\n",
      " Round 7 complete. Avg  = 1.25, Avg Test Acc = 0.80% | Time: 1636.5s\n",
      "  Global Model Metrics after Round 7:\n",
      "    Accuracy:  0.8048\n",
      "    Precision: 0.8106\n",
      "    Recall:    0.8052\n",
      "    F1 Score:  0.8059\n",
      "    Confusion Matrix:\n",
      "[[1820  187  263]\n",
      " [ 115 1916  227]\n",
      " [  91  457 1788]]\n",
      " Saved global model to densenet121\\global_model_round_7.pt\n",
      "\n",
      " -------- Federated Round 8 --------\n",
      " Round 8: Selected 5 out of 6 clients\n",
      "[Client 1] Epoch 1/7, Loss: 74.3840\n",
      "[Client 1] Epoch 2/7, Loss: 77.7201\n",
      "[Client 1] Epoch 3/7, Loss: 75.3360\n",
      "[Client 1] Epoch 4/7, Loss: 73.3553\n",
      "[Client 1] Epoch 5/7, Loss: 75.8326\n",
      "[Client 1] Epoch 6/7, Loss: 83.4172\n",
      "[Client 1] Epoch 7/7, Loss: 78.1678\n",
      "[Client 1] Test Accuracy: 81.64%\n",
      "[Client 1] Training done.  = 1.25\n",
      "[Client 1]  Test Accuracy: 81.64%\n",
      "[Client 5] Epoch 1/7, Loss: 77.7073\n",
      "[Client 5] Epoch 2/7, Loss: 75.2478\n",
      "[Client 5] Epoch 3/7, Loss: 73.4964\n",
      "[Client 5] Epoch 4/7, Loss: 77.2469\n",
      "[Client 5] Epoch 5/7, Loss: 74.6087\n",
      "[Client 5] Epoch 6/7, Loss: 73.9531\n",
      "[Client 5] Epoch 7/7, Loss: 72.7936\n",
      "[Client 5] Test Accuracy: 79.11%\n",
      "[Client 5] Training done.  = 1.25\n",
      "[Client 5]  Test Accuracy: 79.11%\n",
      "[Client 3] Epoch 1/7, Loss: 75.9428\n",
      "[Client 3] Epoch 2/7, Loss: 78.9256\n",
      "[Client 3] Epoch 3/7, Loss: 80.7539\n",
      "[Client 3] Epoch 4/7, Loss: 77.3052\n",
      "[Client 3] Epoch 5/7, Loss: 78.2296\n",
      "[Client 3] Epoch 6/7, Loss: 77.4914\n",
      "[Client 3] Epoch 7/7, Loss: 78.0371\n",
      "[Client 3] Test Accuracy: 82.95%\n",
      "[Client 3] Training done.  = 1.25\n",
      "[Client 3]  Test Accuracy: 82.95%\n",
      "[Client 2] Epoch 1/7, Loss: 72.9789\n",
      "[Client 2] Epoch 2/7, Loss: 74.4404\n",
      "[Client 2] Epoch 3/7, Loss: 77.8805\n",
      "[Client 2] Epoch 4/7, Loss: 74.1303\n",
      "[Client 2] Epoch 5/7, Loss: 78.1643\n",
      "[Client 2] Epoch 6/7, Loss: 76.1789\n",
      "[Client 2] Epoch 7/7, Loss: 75.8944\n",
      "[Client 2] Test Accuracy: 80.51%\n",
      "[Client 2] Training done.  = 1.25\n",
      "[Client 2]  Test Accuracy: 80.51%\n",
      "[Client 0] Epoch 1/7, Loss: 76.6846\n",
      "[Client 0] Epoch 2/7, Loss: 77.0973\n",
      "[Client 0] Epoch 3/7, Loss: 72.6157\n",
      "[Client 0] Epoch 4/7, Loss: 73.7117\n",
      "[Client 0] Epoch 5/7, Loss: 71.1473\n",
      "[Client 0] Epoch 6/7, Loss: 74.2907\n",
      "[Client 0] Epoch 7/7, Loss: 75.0517\n",
      "[Client 0] Test Accuracy: 82.43%\n",
      "[Client 0] Training done.  = 1.25\n",
      "[Client 0]  Test Accuracy: 82.43%\n",
      " Round 8 complete. Avg  = 1.25, Avg Test Acc = 0.81% | Time: 1563.8s\n",
      "  Global Model Metrics after Round 8:\n",
      "    Accuracy:  0.8103\n",
      "    Precision: 0.8151\n",
      "    Recall:    0.8106\n",
      "    F1 Score:  0.8114\n",
      "    Confusion Matrix:\n",
      "[[1834  174  262]\n",
      " [ 117 1901  240]\n",
      " [  90  419 1827]]\n",
      " Saved global model to densenet121\\global_model_round_8.pt\n",
      "\n",
      " -------- Federated Round 9 --------\n",
      " Round 9: Selected 5 out of 6 clients\n",
      "[Client 0] Epoch 1/7, Loss: 75.3973\n",
      "[Client 0] Epoch 2/7, Loss: 72.5607\n",
      "[Client 0] Epoch 3/7, Loss: 74.1001\n",
      "[Client 0] Epoch 4/7, Loss: 72.9179\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 137\u001b[0m\n\u001b[0;32m    134\u001b[0m test_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_dataset) \u001b[38;5;241m-\u001b[39m train_len\n\u001b[0;32m    135\u001b[0m train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m random_split(full_dataset, [train_len, test_len])\n\u001b[1;32m--> 137\u001b[0m updated_weights, epsilon \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_local_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m client_weights\u001b[38;5;241m.\u001b[39mappend(updated_weights)\n\u001b[0;32m    139\u001b[0m epsilons\u001b[38;5;241m.\u001b[39mappend(epsilon)\n",
      "Cell \u001b[1;32mIn[14], line 41\u001b[0m, in \u001b[0;36mtrain_local_model\u001b[1;34m(client_id, model, train_data, test_data, args)\u001b[0m\n\u001b[0;32m     39\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     40\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 41\u001b[0m         running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluation on test set\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import densenet121\n",
    "from PIL import Image\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "MODEL_DIR = \"densenet121\"\n",
    "METRIC_LOG_PATH = \"metrics_log.csv\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Dataset that handles both file paths and PIL images\n",
    "class XrayLazyDataset(Dataset):\n",
    "    def __init__(self, image_label_list, transform=None):\n",
    "        self.image_label_list = image_label_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_label_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_or_path, label = self.image_label_list[idx]\n",
    "\n",
    "        if isinstance(image_or_path, str):\n",
    "            image = Image.open(image_or_path).convert(\"RGB\")\n",
    "        elif isinstance(image_or_path, Image.Image):\n",
    "            image = image_or_path\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported image type: {type(image_or_path)}\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Strip Opacus prefixes if present\n",
    "def strip_opacus_prefix(state_dict):\n",
    "    return {k.replace(\"_module.\", \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataset, args):\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=args.batch_size)\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(args.device), labels.to(args.device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            if outputs.shape[1] != NUM_CLASSES:\n",
    "                raise RuntimeError(f\"Model output shape {outputs.shape[1]}  NUM_CLASSES {NUM_CLASSES}\")\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return acc, prec, rec, f1, cm\n",
    "\n",
    "def create_densenet121_model():\n",
    "    model = densenet121(pretrained=True)\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, NUM_CLASSES)\n",
    "    return model\n",
    "\n",
    "def load_latest_model():\n",
    "    files = [f for f in os.listdir(MODEL_DIR) if f.startswith('global_model_round_') and f.endswith('.pt')]\n",
    "    if not files:\n",
    "        print(\"No previously saved model found. Initializing new model.\")\n",
    "        return create_densenet121_model(), 0\n",
    "    latest_round = max([int(f.split('_')[-1].split('.')[0]) for f in files])\n",
    "    latest_file = os.path.join(MODEL_DIR, f\"global_model_round_{latest_round}.pt\")\n",
    "    print(f\"Loading model from {latest_file}\")\n",
    "    model = create_densenet121_model()\n",
    "    model.load_state_dict(torch.load(latest_file))\n",
    "    return model, latest_round\n",
    "\n",
    "global_model, start_round = load_latest_model()\n",
    "global_model = global_model.to(args.device)\n",
    "global_weights = global_model.state_dict()\n",
    "epsilon_tracker = []\n",
    "round_times = []\n",
    "test_accuracies = []\n",
    "\n",
    "if not os.path.isfile(METRIC_LOG_PATH):\n",
    "    with open(METRIC_LOG_PATH, 'w') as f:\n",
    "        f.write(\"Round,Accuracy,Precision,Recall,F1,ConfusionMatrix\\n\")\n",
    "\n",
    "for round_idx in range(start_round, args.round_count):\n",
    "    print(f\"\\n -------- Federated Round {round_idx + 1} --------\")\n",
    "\n",
    "    selected_clients = select_clients(client_datasets, round_idx, drop_rate=args.drop_rate)\n",
    "    client_weights = []\n",
    "    epsilons = []\n",
    "    round_test_acc = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for client_id in selected_clients:\n",
    "        client_data = client_datasets[client_id]\n",
    "\n",
    "        client_data_list = client_data['train'] + client_data['test']\n",
    "        client_data_list = [\n",
    "            (p, l) for (p, l) in client_data_list\n",
    "            if (isinstance(p, str) and os.path.isfile(p)) or isinstance(p, Image.Image)\n",
    "        ]\n",
    "\n",
    "        if len(client_data_list) == 0:\n",
    "            print(f\"[Skip] Client {client_id} has no valid data.\")\n",
    "            continue\n",
    "\n",
    "        full_dataset = XrayLazyDataset(client_data_list, transform=img_transform)\n",
    "        train_len = int(0.8 * len(full_dataset))\n",
    "        test_len = len(full_dataset) - train_len\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_len, test_len])\n",
    "\n",
    "        updated_weights, epsilon = train_local_model(client_id, global_model, train_dataset, test_dataset, args)\n",
    "        client_weights.append(updated_weights)\n",
    "        epsilons.append(epsilon)\n",
    "\n",
    "        temp_model = copy.deepcopy(global_model).to(args.device)\n",
    "        temp_model.load_state_dict(strip_opacus_prefix(updated_weights))\n",
    "        acc = evaluate_model(temp_model, test_dataset, args)[0]\n",
    "        round_test_acc.append(acc)\n",
    "        # print(f\"[Client {client_id}]  Test Accuracy: {acc:.2f}%\")\n",
    "        print(f\"[Client {client_id}]  Test Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "    if client_weights:\n",
    "        global_weights = fed_avg(client_weights)\n",
    "        global_weights = strip_opacus_prefix(global_weights)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        avg_epsilon = sum(epsilons) / len(epsilons)\n",
    "        avg_test_acc = sum(round_test_acc) / len(round_test_acc)\n",
    "        epsilon_tracker.append(avg_epsilon)\n",
    "        test_accuracies.append(avg_test_acc)\n",
    "\n",
    "        round_time = time.time() - start_time\n",
    "        round_times.append(round_time)\n",
    "\n",
    "        print(f\" Round {round_idx + 1} complete. Avg  = {avg_epsilon:.2f}, Avg Test Acc = {avg_test_acc:.2f}% | Time: {round_time:.1f}s\")\n",
    "\n",
    "        combined_test_data = []\n",
    "        for cid, cdata in client_datasets.items():\n",
    "            combined_test_data += [\n",
    "                (p, l) for (p, l) in cdata['test']\n",
    "                if (isinstance(p, str) and os.path.isfile(p)) or isinstance(p, Image.Image)\n",
    "            ]\n",
    "\n",
    "        if len(combined_test_data) > 0:\n",
    "            global_test_dataset = XrayLazyDataset(combined_test_data, transform=img_transform)\n",
    "            acc, prec, rec, f1, cm = evaluate_model(global_model.to(args.device), global_test_dataset, args)\n",
    "            print(f\"  Global Model Metrics after Round {round_idx + 1}:\")\n",
    "            print(f\"    Accuracy:  {acc:.4f}\")\n",
    "            print(f\"    Precision: {prec:.4f}\")\n",
    "            print(f\"    Recall:    {rec:.4f}\")\n",
    "            print(f\"    F1 Score:  {f1:.4f}\")\n",
    "            print(f\"    Confusion Matrix:\\n{cm}\")\n",
    "            with open(METRIC_LOG_PATH, 'a') as f:\n",
    "                f.write(f\"{round_idx + 1},{acc:.4f},{prec:.4f},{rec:.4f},{f1:.4f},\\\"{cm.tolist()}\\\"\\n\")\n",
    "        else:\n",
    "            print(\" No valid test data found for global model evaluation.\")\n",
    "\n",
    "        model_path = os.path.join(MODEL_DIR, f\"global_model_round_{round_idx+1}.pt\")\n",
    "        torch.save(global_model.state_dict(), model_path)\n",
    "        print(f\" Saved global model to {model_path}\")\n",
    "    else:\n",
    "        print(\" No valid client updates this round. Skipping FedAvg.\")\n",
    "\n",
    "print(\"\\n Federated training finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
